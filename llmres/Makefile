
train:
	mlx_lm.lora --model mlx-community/Qwen3-8B-Instruct --train --data data --iters 10 --batch-size 1 --num-layers 4